{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 5 crossarms, 1 polo, 13 wires, 16.0ms\n",
      "Speed: 3.0ms preprocess, 16.0ms inference, 49.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 5 crossarms, 1 polo, 15 wires, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Image 1: 17 objects detected\n",
      "Image 2: 20 objects detected\n",
      "Added objects: 3\n",
      "Removed objects: 0\n",
      "\n",
      "Class distribution in Image 1:\n",
      "Class 2: 11\n",
      "Class 0: 5\n",
      "Class 1: 1\n",
      "\n",
      "Class distribution in Image 2:\n",
      "Class 2: 14\n",
      "Class 0: 5\n",
      "Class 1: 1\n"
     ]
    }
   ],
   "source": [
    "# 2D CNN\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# 2D CNN 모델 정의\n",
    "class Simple2DCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Simple2DCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(64 * 160 * 160, 512)  # 640x640 크기에 맞게 조정\n",
    "        self.fc2 = nn.Linear(512, 2)  # 예시: 클래스가 2개 (변화 감지, 비변화)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = x.view(-1, 64 * 160 * 160)  # Flatten\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "def extract_objects(results, confidence_threshold):\n",
    "    objects = []\n",
    "    for r in results.boxes.data.tolist():\n",
    "        x1, y1, x2, y2, score, class_id = r\n",
    "        if score > confidence_threshold:\n",
    "            objects.append({\n",
    "                'bbox': [int(x1), int(y1), int(x2), int(y2)],\n",
    "                'score': score,\n",
    "                'class_id': int(class_id)\n",
    "            })\n",
    "    return objects\n",
    "\n",
    "def compare_objects(objects1, objects2, iou_threshold):\n",
    "    added = []\n",
    "    removed = []\n",
    "    \n",
    "    matched1 = set()\n",
    "    matched2 = set()\n",
    "    \n",
    "    for i, obj1 in enumerate(objects1):\n",
    "        for j, obj2 in enumerate(objects2):\n",
    "            if i in matched1 or j in matched2:\n",
    "                continue\n",
    "            \n",
    "            iou = calculate_iou(obj1['bbox'], obj2['bbox'])\n",
    "            if iou > iou_threshold:\n",
    "                matched1.add(i)\n",
    "                matched2.add(j)\n",
    "                break\n",
    "        \n",
    "        if i not in matched1:\n",
    "            removed.append(obj1)\n",
    "    \n",
    "    for j, obj2 in enumerate(objects2):\n",
    "        if j not in matched2:\n",
    "            added.append(obj2)\n",
    "    \n",
    "    return added, removed\n",
    "\n",
    "def calculate_iou(box1, box2):\n",
    "    x1 = max(box1[0], box2[0])\n",
    "    y1 = max(box1[1], box2[1])\n",
    "    x2 = min(box1[2], box2[2])\n",
    "    y2 = min(box1[3], box2[3])\n",
    "    \n",
    "    intersection = max(0, x2 - x1) * max(0, y2 - y1)\n",
    "    area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "    area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "    \n",
    "    iou = intersection / float(area1 + area2 - intersection)\n",
    "    return iou\n",
    "    pass    \n",
    "\n",
    "def visualize_changes(image1, image2, added, removed):\n",
    "    result_image = np.hstack((image1, image2))\n",
    "    height, width = image1.shape[:2]\n",
    "    \n",
    "    for obj in added:\n",
    "        x1, y1, x2, y2 = obj['bbox']\n",
    "        cv2.rectangle(result_image, (x1 + width, y1), (x2 + width, y2), (0, 255, 0), 2)\n",
    "        cv2.putText(result_image, 'Added', (x1 + width, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "    \n",
    "    for obj in removed:\n",
    "        x1, y1, x2, y2 = obj['bbox']\n",
    "        cv2.rectangle(result_image, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "        cv2.putText(result_image, 'Removed', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)\n",
    "    \n",
    "    cv2.imshow('Changes Detected', result_image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    pass\n",
    "\n",
    "def analyze_results(objects1, objects2, added, removed):\n",
    "    print(f\"Image 1: {len(objects1)} objects detected\")\n",
    "    print(f\"Image 2: {len(objects2)} objects detected\")\n",
    "    print(f\"Added objects: {len(added)}\")\n",
    "    print(f\"Removed objects: {len(removed)}\")\n",
    "    \n",
    "    class_counts1 = {}\n",
    "    class_counts2 = {}\n",
    "    \n",
    "    for obj in objects1:\n",
    "        class_counts1[obj['class_id']] = class_counts1.get(obj['class_id'], 0) + 1\n",
    "    \n",
    "    for obj in objects2:\n",
    "        class_counts2[obj['class_id']] = class_counts2.get(obj['class_id'], 0) + 1\n",
    "    \n",
    "    print(\"\\nClass distribution in Image 1:\")\n",
    "    for class_id, count in class_counts1.items():\n",
    "        print(f\"Class {class_id}: {count}\")\n",
    "    \n",
    "    print(\"\\nClass distribution in Image 2:\")\n",
    "    for class_id, count in class_counts2.items():\n",
    "        print(f\"Class {class_id}: {count}\")\n",
    "\n",
    "\n",
    "# 변화 감지 함수\n",
    "def detect_changes_2d(image1_path, image2_path, model_path, cnn_model, confidence_threshold=0.5, iou_threshold=0.5):\n",
    "    # YOLO 모델 로드\n",
    "    model = YOLO(model_path)\n",
    "\n",
    "    # 이미지 로드\n",
    "    image1 = cv2.imread(image1_path)\n",
    "    image2 = cv2.imread(image2_path)\n",
    "\n",
    "    # YOLO를 사용하여 객체 탐지\n",
    "    results1 = model(image1)[0]\n",
    "    results2 = model(image2)[0]\n",
    "\n",
    "    # 객체 추출\n",
    "    objects1 = extract_objects(results1, confidence_threshold)\n",
    "    objects2 = extract_objects(results2, confidence_threshold)\n",
    "\n",
    "    # 객체 비교 (기존 방식 유지)\n",
    "    added, removed = compare_objects(objects1, objects2, iou_threshold)\n",
    "\n",
    "    # 이미지를 2D CNN에 입력\n",
    "    image1_2d = prepare_image_for_2d_cnn(image1)\n",
    "    image2_2d = prepare_image_for_2d_cnn(image2)\n",
    "\n",
    "    # 2D CNN을 통한 특징 추출 및 변화 감지\n",
    "    features1 = cnn_model(image1_2d)\n",
    "    features2 = cnn_model(image2_2d)\n",
    "    \n",
    "    difference = compute_difference_2d(features1, features2)\n",
    "\n",
    "    # 결과 시각화\n",
    "    visualize_changes(image1, image2, added, removed)\n",
    "\n",
    "    # 결과 분석\n",
    "    analyze_results(objects1, objects2, added, removed)\n",
    "\n",
    "# 2D CNN에 입력할 이미지를 준비하는 함수\n",
    "def prepare_image_for_2d_cnn(image):\n",
    "    # 이미지를 2D CNN에 입력할 수 있도록 변환\n",
    "    image = cv2.resize(image, (640, 640))\n",
    "    image_2d = np.transpose(image, (2, 0, 1))  # (H, W, C) -> (C, H, W)\n",
    "    return torch.Tensor(image_2d).unsqueeze(0)  # (B, C, H, W)\n",
    "\n",
    "# 2D CNN을 통한 특징 비교 함수\n",
    "def compute_difference_2d(features1, features2):\n",
    "    # 간단한 유클리드 거리 계산\n",
    "    return torch.norm(features1 - features2, p=2).item()\n",
    "\n",
    "# 나머지 기존 함수들 유지 (extract_objects, compare_objects, calculate_iou, visualize_changes, analyze_results)\n",
    "\n",
    "# CNN 모델 초기화\n",
    "cnn_model = Simple2DCNN()\n",
    "\n",
    "# 사용 예시\n",
    "image1_path = 'C:/Users/AI-LHJ/Downloads/source/ch5/test 1.jpg'\n",
    "image2_path = 'C:/Users/AI-LHJ/Downloads/source/ch5/test 2.jpg'\n",
    "model_path = 'C:/Users/AI-LHJ/Desktop/ultralytics-main/runs/segment/train8 best/weights/best.pt'\n",
    "\n",
    "detect_changes_2d(image1_path, image2_path, model_path, cnn_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 1: 11 objects detected\n",
      "Image 2: 11 objects detected\n",
      "Added objects: 0\n",
      "Removed objects: 0\n",
      "\n",
      "Class distribution in Image 1:\n",
      "Class 0: 2\n",
      "Class 2: 8\n",
      "Class 1: 1\n",
      "\n",
      "Class distribution in Image 2:\n",
      "Class 0: 2\n",
      "Class 2: 8\n",
      "Class 1: 1\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from ultralytics import YOLO\n",
    "\n",
    "class Simple2DCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Simple2DCNN, self).__init__()\n",
    "        # 더 깊은 CNN 구조로 변경\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.batch_norm1 = nn.BatchNorm2d(64)\n",
    "        self.batch_norm2 = nn.BatchNorm2d(128)\n",
    "        self.batch_norm3 = nn.BatchNorm2d(256)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(256 * 80 * 80, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.batch_norm1(self.conv1(x))))\n",
    "        x = self.pool(torch.relu(self.batch_norm2(self.conv2(x))))\n",
    "        x = self.pool(torch.relu(self.batch_norm3(self.conv3(x))))\n",
    "        x = x.view(-1, 256 * 80 * 80)\n",
    "        x = self.dropout(torch.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "def extract_objects(results, confidence_threshold):\n",
    "    objects = []\n",
    "    # 신뢰도 점수에 따른 정렬 추가\n",
    "    boxes = sorted(results.boxes.data.tolist(), key=lambda x: x[4], reverse=True)\n",
    "    \n",
    "    for r in boxes:\n",
    "        x1, y1, x2, y2, score, class_id = r\n",
    "        if score > confidence_threshold:\n",
    "            # 바운딩 박스 정규화 추가\n",
    "            x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])\n",
    "            w, h = x2 - x1, y2 - y1\n",
    "            if w > 0 and h > 0:  # 유효한 바운딩 박스만 추가\n",
    "                objects.append({\n",
    "                    'bbox': [x1, y1, x2, y2],\n",
    "                    'score': score,\n",
    "                    'class_id': int(class_id),\n",
    "                    'area': w * h  # 면적 정보 추가\n",
    "                })\n",
    "    return objects\n",
    "\n",
    "def compare_objects(objects1, objects2, iou_threshold):\n",
    "    added = []\n",
    "    removed = []\n",
    "    matched1 = set()\n",
    "    matched2 = set()\n",
    "    \n",
    "    # 면적 기반 정렬 추가\n",
    "    objects1 = sorted(objects1, key=lambda x: x['area'], reverse=True)\n",
    "    objects2 = sorted(objects2, key=lambda x: x['area'], reverse=True)\n",
    "    \n",
    "    for i, obj1 in enumerate(objects1):\n",
    "        best_iou = iou_threshold\n",
    "        best_match = -1\n",
    "        \n",
    "        for j, obj2 in enumerate(objects2):\n",
    "            if j in matched2:\n",
    "                continue\n",
    "                \n",
    "            iou = calculate_iou(obj1['bbox'], obj2['bbox'])\n",
    "            # 클래스 ID가 같은 경우에만 매칭\n",
    "            if iou > best_iou and obj1['class_id'] == obj2['class_id']:\n",
    "                best_iou = iou\n",
    "                best_match = j\n",
    "        \n",
    "        if best_match >= 0:\n",
    "            matched1.add(i)\n",
    "            matched2.add(best_match)\n",
    "        else:\n",
    "            removed.append(obj1)\n",
    "    \n",
    "    for j, obj2 in enumerate(objects2):\n",
    "        if j not in matched2:\n",
    "            added.append(obj2)\n",
    "    \n",
    "    return added, removed\n",
    "\n",
    "def detect_changes_2d(image1_path, image2_path, model_path, cnn_model, \n",
    "                     confidence_threshold=0.45,  # 신뢰도 임계값 조정\n",
    "                     iou_threshold=0.4):        # IOU 임계값 조정\n",
    "    # YOLO 모델 로드 및 설정\n",
    "    model = YOLO(model_path)\n",
    "    model.conf = confidence_threshold  # 모델 신뢰도 임계값 설정\n",
    "    model.iou = iou_threshold         # 모델 IOU 임계값 설정\n",
    "    \n",
    "    # 이미지 로드 및 전처리\n",
    "    image1 = cv2.imread(image1_path)\n",
    "    image2 = cv2.imread(image2_path)\n",
    "    \n",
    "    # 이미지 크기 정규화\n",
    "    target_size = (640, 640)\n",
    "    image1 = cv2.resize(image1, target_size)\n",
    "    image2 = cv2.resize(image2, target_size)\n",
    "    \n",
    "    # YOLO 예측\n",
    "    results1 = model(image1, verbose=False)[0]  # verbose=False로 불필요한 출력 제거\n",
    "    results2 = model(image2, verbose=False)[0]\n",
    "    \n",
    "    # 객체 추출 및 비교\n",
    "    objects1 = extract_objects(results1, confidence_threshold)\n",
    "    objects2 = extract_objects(results2, confidence_threshold)\n",
    "    \n",
    "    # 변화 감지\n",
    "    added, removed = compare_objects(objects1, objects2, iou_threshold)\n",
    "    \n",
    "    # CNN 특징 추출\n",
    "    with torch.no_grad():  # 추론 모드로 변경\n",
    "        image1_2d = prepare_image_for_2d_cnn(image1)\n",
    "        image2_2d = prepare_image_for_2d_cnn(image2)\n",
    "        features1 = cnn_model(image1_2d)\n",
    "        features2 = cnn_model(image2_2d)\n",
    "    \n",
    "    # 결과 시각화 및 분석\n",
    "    visualize_changes(image1, image2, added, removed)\n",
    "    analyze_results(objects1, objects2, added, removed)\n",
    "    \n",
    "    return added, removed\n",
    "\n",
    "def prepare_image_for_2d_cnn(image):\n",
    "    # 이미지 정규화 추가\n",
    "    image = image.astype(np.float32) / 255.0\n",
    "    image = np.transpose(image, (2, 0, 1))\n",
    "    image = torch.Tensor(image).unsqueeze(0)\n",
    "    return image\n",
    "\n",
    "# 사용 예시\n",
    "if __name__ == \"__main__\":\n",
    "    image1_path = 'C:/Users/AI-LHJ/Downloads/source/ch5/test 7.jpg'\n",
    "    image2_path = 'C:/Users/AI-LHJ/Downloads/source/ch5/test 8.jpg'\n",
    "    model_path = 'C:/Users/AI-LHJ/Desktop/ultralytics-main/runs/segment/train8 best/weights/best.pt'\n",
    "    \n",
    "    # CNN 모델 초기화 및 평가 모드로 설정\n",
    "    cnn_model = Simple2DCNN()\n",
    "    cnn_model.eval()\n",
    "    \n",
    "    # 변화 감지 실행\n",
    "    detect_changes_2d(image1_path, image2_path, model_path, cnn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 4 crossarms, 1 polo, 15 wires, 18.3ms\n",
      "Speed: 2.0ms preprocess, 18.3ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 4 crossarms, 1 polo, 19 wires, 20.1ms\n",
      "Speed: 2.6ms preprocess, 20.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Change probability: 36.46%\n",
      "Change detected: False\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from ultralytics import YOLO\n",
    "\n",
    "class Simple2DCNN(nn.Module):\n",
    "    def __init__(self, input_channels=3):\n",
    "        super(Simple2DCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channels, 64, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.batch_norm1 = nn.BatchNorm2d(64)\n",
    "        self.batch_norm2 = nn.BatchNorm2d(128)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(128 * 160 * 160, 512)\n",
    "        self.fc2 = nn.Linear(512, 2)  # 변화 있음/없음 분류\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.batch_norm1(self.conv1(x))))\n",
    "        x = self.pool(torch.relu(self.batch_norm2(self.conv2(x))))\n",
    "        x = x.view(-1, 128 * 160 * 160)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "def create_detection_map(image_shape, detections, confidence_threshold=0.25):\n",
    "    \"\"\"YOLO 검출 결과를 히트맵으로 변환\"\"\"\n",
    "    detection_map = np.zeros(image_shape[:2], dtype=np.float32)\n",
    "    \n",
    "    for det in detections.boxes.data.tolist():\n",
    "        x1, y1, x2, y2, conf, cls = det\n",
    "        if conf > confidence_threshold:\n",
    "            x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])\n",
    "            detection_map[y1:y2, x1:x2] = conf\n",
    "    \n",
    "    return detection_map\n",
    "\n",
    "def detect_changes(image1_path, image2_path, yolo_model_path, cnn_model=None):\n",
    "    # YOLO 모델 로드\n",
    "    yolo = YOLO(yolo_model_path)\n",
    "    \n",
    "    # 이미지 로드 및 크기 조정\n",
    "    image1 = cv2.imread(image1_path)\n",
    "    image2 = cv2.imread(image2_path)\n",
    "    \n",
    "    target_size = (640, 640)\n",
    "    image1 = cv2.resize(image1, target_size)\n",
    "    image2 = cv2.resize(image2, target_size)\n",
    "    \n",
    "    # YOLO로 객체 검출\n",
    "    results1 = yolo(image1)[0]\n",
    "    results2 = yolo(image2)[0]\n",
    "    \n",
    "    # 검출 결과를 히트맵으로 변환\n",
    "    detection_map1 = create_detection_map(image1.shape, results1)\n",
    "    detection_map2 = create_detection_map(image2.shape, results2)\n",
    "    \n",
    "    # 검출 맵을 3채널로 확장 (CNN 입력용)\n",
    "    detection_maps = np.stack([\n",
    "        detection_map1,\n",
    "        detection_map2,\n",
    "        np.abs(detection_map1 - detection_map2)\n",
    "    ], axis=2)\n",
    "    \n",
    "    # 결과 시각화\n",
    "    visualize_results(image1, image2, detection_map1, detection_map2, results1, results2)\n",
    "    \n",
    "    # CNN 모델이 제공된 경우 변화 분류 수행\n",
    "    if cnn_model is not None:\n",
    "        with torch.no_grad():\n",
    "            # 입력 데이터 준비\n",
    "            input_tensor = torch.FloatTensor(detection_maps).permute(2, 0, 1).unsqueeze(0)\n",
    "            \n",
    "            # 변화 예측\n",
    "            prediction = cnn_model(input_tensor)\n",
    "            probability = torch.softmax(prediction, dim=1)\n",
    "            change_prob = probability[0][1].item()\n",
    "            \n",
    "            print(f\"Change probability: {change_prob:.2%}\")\n",
    "            return change_prob > 0.5\n",
    "    \n",
    "    return None\n",
    "\n",
    "def visualize_results(image1, image2, map1, map2, yolo_results1, yolo_results2):\n",
    "    # YOLO 검출 결과 시각화\n",
    "    det_image1 = image1.copy()\n",
    "    det_image2 = image2.copy()\n",
    "    \n",
    "    # YOLO 바운딩 박스 그리기\n",
    "    for result, img in [(yolo_results1, det_image1), (yolo_results2, det_image2)]:\n",
    "        for box in result.boxes.data.tolist():\n",
    "            x1, y1, x2, y2, conf, cls = box\n",
    "            if conf > 0.25:  # 신뢰도 임계값\n",
    "                x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])\n",
    "                cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                cv2.putText(img, f'{conf:.2f}', (x1, y1-10),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "    \n",
    "    # 히트맵 시각화\n",
    "    map1_colored = cv2.applyColorMap((map1 * 255).astype(np.uint8), cv2.COLORMAP_JET)\n",
    "    map2_colored = cv2.applyColorMap((map2 * 255).astype(np.uint8), cv2.COLORMAP_JET)\n",
    "    \n",
    "    # 결과 합치기\n",
    "    top_row = np.hstack((det_image1, det_image2))\n",
    "    bottom_row = np.hstack((map1_colored, map2_colored))\n",
    "    combined = np.vstack((top_row, bottom_row))\n",
    "    \n",
    "    # 창 크기 조정\n",
    "    scale = 0.7\n",
    "    display_size = (int(combined.shape[1] * scale), int(combined.shape[0] * scale))\n",
    "    combined = cv2.resize(combined, display_size)\n",
    "    \n",
    "    cv2.imshow('Detection Results', combined)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    image1_path = 'C:/Users/AI-LHJ/Downloads/source/ch5/test 5.jpg'\n",
    "    image2_path = 'C:/Users/AI-LHJ/Downloads/source/ch5/test 6.jpg'\n",
    "    yolo_model_path = 'C:/Users/AI-LHJ/Desktop/ultralytics-main/runs/segment/train8 best/weights/best.pt'\n",
    "    \n",
    "    # 2D CNN 모델 초기화 (선택적)\n",
    "    cnn_model = Simple2DCNN(input_channels=3)\n",
    "    \n",
    "    # 변화 감지 실행\n",
    "    result = detect_changes(image1_path, image2_path, yolo_model_path, cnn_model)\n",
    "    \n",
    "    if result is not None:\n",
    "        print(f\"Change detected: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 2 crossarms, 1 polo, 15 wires, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 crossarms, 1 polo, 18 wires, 19.0ms\n",
      "Speed: 3.0ms preprocess, 19.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "Change Detection Results:\n",
      "Total objects in first image: 18\n",
      "Total objects in second image: 21\n",
      "Disappeared objects: 0\n",
      "Appeared objects: 3\n",
      "\n",
      "Appeared objects details:\n",
      "Class: 2, Confidence: 0.94\n",
      "Class: 2, Confidence: 0.89\n",
      "Class: 2, Confidence: 0.46\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "def calculate_iou(box1, box2):\n",
    "    \"\"\"두 바운딩 박스 간의 IoU 계산\"\"\"\n",
    "    x1 = max(box1[0], box2[0])\n",
    "    y1 = max(box1[1], box2[1])\n",
    "    x2 = min(box1[2], box2[2])\n",
    "    y2 = min(box1[3], box2[3])\n",
    "    \n",
    "    intersection = max(0, x2 - x1) * max(0, y2 - y1)\n",
    "    area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "    area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "    \n",
    "    iou = intersection / float(area1 + area2 - intersection + 1e-6)\n",
    "    return iou\n",
    "\n",
    "def detect_object_changes(image1_path, image2_path, yolo_model_path, conf_threshold=0.25, iou_threshold=0.5):\n",
    "    # YOLO 모델 로드\n",
    "    model = YOLO(yolo_model_path)\n",
    "    \n",
    "    # 이미지 로드\n",
    "    image1 = cv2.imread(image1_path)\n",
    "    image2 = cv2.imread(image2_path)\n",
    "    \n",
    "    # 이미지 크기 조정\n",
    "    target_size = (640, 640)\n",
    "    image1 = cv2.resize(image1, target_size)\n",
    "    image2 = cv2.resize(image2, target_size)\n",
    "    \n",
    "    # YOLO로 객체 검출\n",
    "    results1 = model(image1)[0]\n",
    "    results2 = model(image2)[0]\n",
    "    \n",
    "    # 검출 결과 추출\n",
    "    boxes1 = []\n",
    "    boxes2 = []\n",
    "    \n",
    "    for r in results1.boxes.data.tolist():\n",
    "        x1, y1, x2, y2, conf, cls = r\n",
    "        if conf > conf_threshold:\n",
    "            boxes1.append({\n",
    "                'box': [int(x1), int(y1), int(x2), int(y2)],\n",
    "                'conf': conf,\n",
    "                'class': int(cls),\n",
    "                'matched': False\n",
    "            })\n",
    "    \n",
    "    for r in results2.boxes.data.tolist():\n",
    "        x1, y1, x2, y2, conf, cls = r\n",
    "        if conf > conf_threshold:\n",
    "            boxes2.append({\n",
    "                'box': [int(x1), int(y1), int(x2), int(y2)],\n",
    "                'conf': conf,\n",
    "                'class': int(cls),\n",
    "                'matched': False\n",
    "            })\n",
    "    \n",
    "    # 객체 매칭 및 변화 감지\n",
    "    disappeared = []  # 사라진 객체\n",
    "    appeared = []    # 새로 나타난 객체\n",
    "    \n",
    "    # 같은 객체 매칭\n",
    "    for i, obj1 in enumerate(boxes1):\n",
    "        best_iou = iou_threshold\n",
    "        best_match = -1\n",
    "        \n",
    "        for j, obj2 in enumerate(boxes2):\n",
    "            if obj2['matched'] or obj1['class'] != obj2['class']:\n",
    "                continue\n",
    "                \n",
    "            iou = calculate_iou(obj1['box'], obj2['box'])\n",
    "            if iou > best_iou:\n",
    "                best_iou = iou\n",
    "                best_match = j\n",
    "        \n",
    "        if best_match >= 0:\n",
    "            boxes1[i]['matched'] = True\n",
    "            boxes2[best_match]['matched'] = True\n",
    "        else:\n",
    "            disappeared.append(obj1)\n",
    "    \n",
    "    # 새로 나타난 객체 찾기\n",
    "    for obj2 in boxes2:\n",
    "        if not obj2['matched']:\n",
    "            appeared.append(obj2)\n",
    "    \n",
    "    # 결과 시각화\n",
    "    def create_visualization(image1, image2, disappeared, appeared):\n",
    "        # 원본 이미지 복사\n",
    "        vis_img1 = image1.copy()\n",
    "        vis_img2 = image2.copy()\n",
    "        \n",
    "        # 사라진 객체 표시 (빨간색)\n",
    "        for obj in disappeared:\n",
    "            x1, y1, x2, y2 = obj['box']\n",
    "            cv2.rectangle(vis_img1, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "            cv2.putText(vis_img1, f'Disappeared (conf: {obj[\"conf\"]:.2f})', \n",
    "                       (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "        \n",
    "        # 새로 나타난 객체 표시 (초록색)\n",
    "        for obj in appeared:\n",
    "            x1, y1, x2, y2 = obj['box']\n",
    "            cv2.rectangle(vis_img2, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(vis_img2, f'Appeared (conf: {obj[\"conf\"]:.2f})', \n",
    "                       (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "        \n",
    "        # 히트맵 생성\n",
    "        heatmap1 = np.zeros(image1.shape[:2], dtype=np.float32)\n",
    "        heatmap2 = np.zeros(image2.shape[:2], dtype=np.float32)\n",
    "        \n",
    "        # 사라진 객체 히트맵\n",
    "        for obj in disappeared:\n",
    "            x1, y1, x2, y2 = obj['box']\n",
    "            heatmap1[y1:y2, x1:x2] = obj['conf']\n",
    "        \n",
    "        # 새로 나타난 객체 히트맵\n",
    "        for obj in appeared:\n",
    "            x1, y1, x2, y2 = obj['box']\n",
    "            heatmap2[y1:y2, x1:x2] = obj['conf']\n",
    "        \n",
    "        # 히트맵 컬러 변환\n",
    "        heatmap1_colored = cv2.applyColorMap((heatmap1 * 255).astype(np.uint8), cv2.COLORMAP_JET)\n",
    "        heatmap2_colored = cv2.applyColorMap((heatmap2 * 255).astype(np.uint8), cv2.COLORMAP_JET)\n",
    "        \n",
    "        # 결과 합치기\n",
    "        alpha = 0.3\n",
    "        overlay1 = cv2.addWeighted(vis_img1, 1 - alpha, heatmap1_colored, alpha, 0)\n",
    "        overlay2 = cv2.addWeighted(vis_img2, 1 - alpha, heatmap2_colored, alpha, 0)\n",
    "        \n",
    "        # 최종 결과 이미지 생성\n",
    "        result = np.hstack((overlay1, overlay2))\n",
    "        \n",
    "        return result, heatmap1_colored, heatmap2_colored\n",
    "    \n",
    "    # 시각화 실행\n",
    "    result_image, hmap1, hmap2 = create_visualization(image1, image2, disappeared, appeared)\n",
    "    \n",
    "    # 결과 출력\n",
    "    cv2.imshow('Object Changes', result_image)\n",
    "    \n",
    "    # 분석 결과 출력\n",
    "    print(\"\\nChange Detection Results:\")\n",
    "    print(f\"Total objects in first image: {len(boxes1)}\")\n",
    "    print(f\"Total objects in second image: {len(boxes2)}\")\n",
    "    print(f\"Disappeared objects: {len(disappeared)}\")\n",
    "    print(f\"Appeared objects: {len(appeared)}\")\n",
    "    \n",
    "    if disappeared:\n",
    "        print(\"\\nDisappeared objects details:\")\n",
    "        for obj in disappeared:\n",
    "            print(f\"Class: {obj['class']}, Confidence: {obj['conf']:.2f}\")\n",
    "    \n",
    "    if appeared:\n",
    "        print(\"\\nAppeared objects details:\")\n",
    "        for obj in appeared:\n",
    "            print(f\"Class: {obj['class']}, Confidence: {obj['conf']:.2f}\")\n",
    "    \n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    return disappeared, appeared\n",
    "\n",
    "# 실행 코드\n",
    "if __name__ == \"__main__\":\n",
    "    image1_path = 'C:/Users/AI-LHJ/Downloads/source/ch5/test 3.jpg'\n",
    "    image2_path = 'C:/Users/AI-LHJ/Downloads/source/ch5/test 4.jpg'\n",
    "    yolo_model_path = 'C:/Users/AI-LHJ/Desktop/ultralytics-main/runs/segment/train8 best/weights/best.pt'\n",
    "    \n",
    "    disappeared, appeared = detect_object_changes(\n",
    "        image1_path, \n",
    "        image2_path, \n",
    "        yolo_model_path,\n",
    "        conf_threshold=0.25,  # 신뢰도 임계값\n",
    "        iou_threshold=0.5     # IoU 임계값\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Yolov8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
